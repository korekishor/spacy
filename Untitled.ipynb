{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f689b494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dr\n",
      "1 .\n",
      "2 strange\n",
      "3 visit\n",
      "4 in\n",
      "5 india\n",
      "6 and\n",
      "7 eat\n",
      "8 pavbhaji\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange visit in india and eat pavbhaji\")\n",
    "for tokne in doc:\n",
    "    print(tokne.i,tokne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e1289a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dr"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6de2b683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kishor@gmail.com\n",
      "harsh@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange visit in india and eat pavbhaji. kishor@gmail.com, harsh@gmail.com\")\n",
    "for token in doc:\n",
    "#     print(tokne.i,token.like_email)\n",
    "    if token.like_email==True:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eab69738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "nlp=spacy.blank(\"en\")\n",
    "nlp.tokenizer.add_special_case(\"gimme\",[\n",
    "    {ORTH:\"gim\"},\n",
    "    {ORTH:\"me\"}\n",
    "]\n",
    ")\n",
    "\n",
    "doc=nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "token=[token.text for token in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff99b29b",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m nlp\u001b[38;5;241m=\u001b[39mspacy\u001b[38;5;241m.\u001b[39mblank(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m doc\u001b[38;5;241m=\u001b[39mnlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentenses \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentenses)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokens\\doc.pyx:890\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "for sentenses in doc.sents:\n",
    "    print(sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d87e545",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr\n",
      ".\n",
      "strange\n",
      "love\n",
      "to\n",
      "eat\n",
      "vadapav\n",
      "from\n",
      "mumbai\n",
      ".\n",
      "hulk\n",
      "love\n",
      "to\n",
      "eat\n",
      "pavbhaji\n",
      "from\n",
      "pune\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    " \n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6e3f11dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x21b5e4aef20>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x21b5e4aee60>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x21b6c8d0430>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x21b6c7abf40>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x21b6c6affc0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x21b6c8d0200>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7c0793d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr  |  PROPN  |  13167435108700103010\n",
      ".  |  PROPN  |  12646065887601541794\n",
      "strange  |  PROPN  |  8371520351987192855\n",
      "love  |  NOUN  |  3702023516439754181\n",
      "to  |  PART  |  3791531372978436496\n",
      "eat  |  VERB  |  9837207709914848172\n",
      "vadapav  |  NOUN  |  2113200769260980851\n",
      "from  |  ADP  |  7831658034963690409\n",
      "mumbai  |  NOUN  |  15245540129409801372\n",
      ".  |  PUNCT  |  12646065887601541794\n",
      "hulk  |  PROPN  |  11597428619500609211\n",
      "love  |  PROPN  |  3702023516439754181\n",
      "to  |  PART  |  3791531372978436496\n",
      "eat  |  VERB  |  9837207709914848172\n",
      "pavbhaji  |  NOUN  |  766411756897414679\n",
      "from  |  ADP  |  7831658034963690409\n",
      "pune  |  NOUN  |  3399371889671182923\n"
     ]
    }
   ],
   "source": [
    " \n",
    "nlp.pipe_names\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipeline\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.pos_,\" | \",token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e150214b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp=spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"ner\",source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee57f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- stemming  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cef00516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating | eat\n",
      "aat | aat\n",
      "eat | eat\n",
      "adjastable | adjast\n",
      "adjast | adjast\n",
      "ability | abil\n",
      "meeting | meet\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import PorterStemmer\n",
    "stremmer=PorterStemmer()\n",
    "words=['eating','aat','eat','adjastable','adjast','ability','meeting']\n",
    "\n",
    "for word in words:\n",
    "    print(word,\"|\",stremmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b25613ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eb43c389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37074ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------part of speech tokne.pose_ which give you the pasrt \n",
    "#    of speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a79d5f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr | | PROPN\n",
      ". | | PROPN\n",
      "strange | | PROPN\n",
      "love | | NOUN\n",
      "to | | PART\n",
      "eat | | VERB\n",
      "vadapav | | NOUN\n",
      "from | | ADP\n",
      "mumbai | | NOUN\n",
      ". | | PUNCT\n",
      "hulk | | PROPN\n",
      "love | | PROPN\n",
      "to | | PART\n",
      "eat | | VERB\n",
      "pavbhaji | | NOUN\n",
      "from | | ADP\n",
      "pune | | NOUN\n"
     ]
    }
   ],
   "source": [
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipeline\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "\n",
    "for token in doc:\n",
    "    print(token,\"| |\",token.pos_)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "eb756ec1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesala | GPE | Countries, cities, states\n",
      "45 | MONEY | Monetary values, including unit\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipe_names\n",
    "doc=nlp(\"Tesala inc is going to acuire twitter for $45 billian\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(ent.text,\"|\",ent.label_,\"|\",spacy.explain(ent.label_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73289c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Tesala\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " inc is going to acuire twitter for $\n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    45\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       " billian</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacy import displacy\n",
    "displacy.render(doc,style=\"ent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a45ea90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CARDINAL',\n",
       " 'DATE',\n",
       " 'EVENT',\n",
       " 'FAC',\n",
       " 'GPE',\n",
       " 'LANGUAGE',\n",
       " 'LAW',\n",
       " 'LOC',\n",
       " 'MONEY',\n",
       " 'NORP',\n",
       " 'ORDINAL',\n",
       " 'ORG',\n",
       " 'PERCENT',\n",
       " 'PERSON',\n",
       " 'PRODUCT',\n",
       " 'QUANTITY',\n",
       " 'TIME',\n",
       " 'WORK_OF_ART']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    " nlp.pipe_labels['ner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed9777c",
   "metadata": {},
   "outputs": [],
   "source": [
    " from spacy import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38a103",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
