{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89b3e102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 dr\n",
      "1 .\n",
      "2 strange\n",
      "3 visit\n",
      "4 in\n",
      "5 india\n",
      "6 and\n",
      "7 eat\n",
      "8 pavbhaji\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange visit in india and eat pavbhaji\")\n",
    "for tokne in doc:\n",
    "    print(tokne.i,tokne)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a17e054b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dr"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d9ce37f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kishor@gmail.com\n",
      "harsh@gmail.com\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange visit in india and eat pavbhaji. kishor@gmail.com, harsh@gmail.com\")\n",
    "for token in doc:\n",
    "#     print(tokne.i,token.like_email)\n",
    "    if token.like_email==True:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "210c9bed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "nlp=spacy.blank(\"en\")\n",
    "nlp.tokenizer.add_special_case(\"gimme\",[\n",
    "    {ORTH:\"gim\"},\n",
    "    {ORTH:\"me\"}\n",
    "]\n",
    ")\n",
    "\n",
    "doc=nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "token=[token.text for token in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "469653fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m nlp\u001b[38;5;241m=\u001b[39mspacy\u001b[38;5;241m.\u001b[39mblank(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m doc\u001b[38;5;241m=\u001b[39mnlp(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sentenses \u001b[38;5;129;01min\u001b[39;00m doc\u001b[38;5;241m.\u001b[39msents:\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(sentenses)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\spacy\\tokens\\doc.pyx:890\u001b[0m, in \u001b[0;36msents\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: [E030] Sentence boundaries unset. You can add the 'sentencizer' component to the pipeline with: `nlp.add_pipe('sentencizer')`. Alternatively, add the dependency parser or sentence recognizer, or set sentence boundaries by setting `doc[i].is_sent_start`."
     ]
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "for sentenses in doc.sents:\n",
    "    print(sentenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7125625b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr\n",
      ".\n",
      "strange\n",
      "love\n",
      "to\n",
      "eat\n",
      "vadapav\n",
      "from\n",
      "mumbai\n",
      ".\n",
      "hulk\n",
      "love\n",
      "to\n",
      "eat\n",
      "pavbhaji\n",
      "from\n",
      "pune\n"
     ]
    }
   ],
   "source": [
    "import spacy \n",
    " \n",
    "nlp=spacy.blank(\"en\")\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2f015521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec at 0x21b5e4aef20>),\n",
       " ('tagger', <spacy.pipeline.tagger.Tagger at 0x21b5e4aee60>),\n",
       " ('parser', <spacy.pipeline.dep_parser.DependencyParser at 0x21b6c8d0430>),\n",
       " ('attribute_ruler',\n",
       "  <spacy.pipeline.attributeruler.AttributeRuler at 0x21b6c7abf40>),\n",
       " ('lemmatizer', <spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x21b6c6affc0>),\n",
       " ('ner', <spacy.pipeline.ner.EntityRecognizer at 0x21b6c8d0200>)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3a80be0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dr  |  PROPN  |  13167435108700103010\n",
      ".  |  PROPN  |  12646065887601541794\n",
      "strange  |  PROPN  |  8371520351987192855\n",
      "love  |  NOUN  |  3702023516439754181\n",
      "to  |  PART  |  3791531372978436496\n",
      "eat  |  VERB  |  9837207709914848172\n",
      "vadapav  |  NOUN  |  2113200769260980851\n",
      "from  |  ADP  |  7831658034963690409\n",
      "mumbai  |  NOUN  |  15245540129409801372\n",
      ".  |  PUNCT  |  12646065887601541794\n",
      "hulk  |  PROPN  |  11597428619500609211\n",
      "love  |  PROPN  |  3702023516439754181\n",
      "to  |  PART  |  3791531372978436496\n",
      "eat  |  VERB  |  9837207709914848172\n",
      "pavbhaji  |  NOUN  |  766411756897414679\n",
      "from  |  ADP  |  7831658034963690409\n",
      "pune  |  NOUN  |  3399371889671182923\n"
     ]
    }
   ],
   "source": [
    " \n",
    "nlp.pipe_names\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp.pipeline\n",
    "doc=nlp(\"dr. strange love to eat vadapav from mumbai. hulk love to eat pavbhaji from pune \")\n",
    "for token in doc:\n",
    "    print(token,\" | \",token.pos_,\" | \",token.lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97e2958c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_nlp=spacy.load(\"en_core_web_sm\")\n",
    "nlp=spacy.blank(\"en\")\n",
    "nlp.add_pipe(\"ner\",source=source_nlp)\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a794b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------- stemming  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "843a86a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import spacy\n",
    "from nltk.stem import PoerterStemmer\n",
    "stremmer=PoerterStemmer()\n",
    "words=['eating','aat','eat','adjastable','adjast','ability','meeting']\n",
    "\n",
    "for word in words:\n",
    "    print(word,\"|\",stemmer.steam(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d834f87e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
